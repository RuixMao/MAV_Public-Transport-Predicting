{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMoPtINmq7JYS61ZMAacbq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuixMao/MAV_Public-Transport-Predicting/blob/main/MAV_Predicting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Data Loading*"
      ],
      "metadata": {
        "id": "B-cxo2OqUCvP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "reM1GeSyq7Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ri790f8aSq2D",
        "outputId": "24970f58-e2ff-4b7d-fd73-cef67e97c091"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1b1b987d-9b36-49df-a8b0-43e3d92b740a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1b1b987d-9b36-49df-a8b0-43e3d92b740a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gtfsMavMenetrend.zip to gtfsMavMenetrend (5).zip\n",
            "   agency_id agency_name               agency_url  agency_timezone  \\\n",
            "0        134       ROeEE    http://www2.gysev.hu/  Europe/Budapest   \n",
            "1        140         MÁV  http://www.mav-start.hu  Europe/Budapest   \n",
            "2        198   MAV-START  http://www.mav-start.hu  Europe/Budapest   \n",
            "\n",
            "  agency_lang        agency_phone       agency_fare_url  \n",
            "0          hu    +36 (99) 577-212  https://jegy.mav.hu/  \n",
            "1          hu  +36 (1) 3-49-49-49  https://jegy.mav.hu/  \n",
            "2          hu  +36 (1) 3-49-49-49  https://jegy.mav.hu/  \n",
            "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
            "0        2001       1        1          1         1       1         1       1   \n",
            "1        2002       1        1          1         1       1         0       0   \n",
            "2        2003       1        0          0         0       0         0       0   \n",
            "3        2004       1        1          1         1       1         0       0   \n",
            "4        2005       1        1          1         1       1         0       0   \n",
            "\n",
            "   start_date  end_date  \n",
            "0    20231016  20231022  \n",
            "1    20230626  20230702  \n",
            "2    20230731  20230806  \n",
            "3    20231016  20231022  \n",
            "4    20230918  20230924  \n",
            "   route_id  agency_id route_short_name route_long_name  route_desc  \\\n",
            "0   10007.0        198              NaN    IC 473 ISTER         NaN   \n",
            "1   10007.1        198              NaN     B 473 ISTER         NaN   \n",
            "2    1003.0        198              NaN        B 35244          NaN   \n",
            "3    1004.0        198              NaN        B 35242          NaN   \n",
            "4    1005.0        198              NaN        B 35240          NaN   \n",
            "\n",
            "   route_type                                          route_url route_color  \\\n",
            "0           2                                                NaN         NaN   \n",
            "1           3  https://www.mavcsoport.hu/mav-start/belfoldi-u...      ffff00   \n",
            "2           3  https://www.mavcsoport.hu/mav-start/belfoldi-u...      ffff00   \n",
            "3           3  https://www.mavcsoport.hu/mav-start/belfoldi-u...      ffff00   \n",
            "4           3  https://www.mavcsoport.hu/mav-start/belfoldi-u...      ffff00   \n",
            "\n",
            "  route_text_color  \n",
            "0              NaN  \n",
            "1           000000  \n",
            "2           000000  \n",
            "3           000000  \n",
            "4           000000  \n",
            "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
            "0  10352347     46.902889     19.667613                 15   \n",
            "1  10352347     46.903357     19.670015                 16   \n",
            "2  10352347     46.903420     19.670892                 17   \n",
            "3  10352347     46.894652     19.687171                 31   \n",
            "4  10352347     46.896213     19.695280                 33   \n",
            "\n",
            "   shape_dist_traveled  \n",
            "0                  NaN  \n",
            "1                  NaN  \n",
            "2                  NaN  \n",
            "3                  NaN  \n",
            "4                  NaN  \n",
            "          trip_id arrival_time departure_time  stop_id  stop_sequence  \\\n",
            "0  10352347_2107.     18:47:00       18:47:00     6096          11270   \n",
            "1  10352347_2107.     18:50:00       18:50:00     1895          11300   \n",
            "2  10352347_2107.     18:51:00       18:51:00     1896          11310   \n",
            "3  10352347_2107.     18:56:00       18:57:00     6097          11370   \n",
            "4  10352347_2107.     18:59:00       19:00:00      490          11400   \n",
            "\n",
            "   stop_headsign  pickup_type  drop_off_type  \n",
            "0            NaN            0              0  \n",
            "1            NaN            0              0  \n",
            "2            NaN            0              0  \n",
            "3            NaN            0              0  \n",
            "4            NaN            0              0  \n",
            "   stop_id  stop_code         stop_name  stop_desc   stop_lat   stop_lon  \\\n",
            "0       70        NaN  Búcsúszentlászló        NaN  46.793056  16.932778   \n",
            "1      140        NaN        Angyalföld        NaN  47.549722  19.090000   \n",
            "2      184        NaN      Felsőjánosfa        NaN  46.841389  16.544167   \n",
            "3      185        NaN           Pankasz        NaN  46.835833  16.496111   \n",
            "4      186        NaN         Nagyrákos        NaN  46.827222  16.455556   \n",
            "\n",
            "   zone_id  stop_url  location_type  parent_station  stop_timezone  \\\n",
            "0      NaN       NaN              0             NaN            NaN   \n",
            "1      NaN       NaN              0             NaN            NaN   \n",
            "2      NaN       NaN              0             NaN            NaN   \n",
            "3      NaN       NaN              0             NaN            NaN   \n",
            "4      NaN       NaN              0             NaN            NaN   \n",
            "\n",
            "   wheelchair_boarding  \n",
            "0                    2  \n",
            "1                    2  \n",
            "2                    2  \n",
            "3                    2  \n",
            "4                    2  \n",
            "   route_id  service_id         trip_id trip_headsign  trip_short_name  \\\n",
            "0   25683.0        2107  10352347_2107.     Kecskemét              NaN   \n",
            "1   25683.0        2409  10352347_2409.     Kecskemét              NaN   \n",
            "2   25683.0        2585  10352347_2585.     Kecskemét              NaN   \n",
            "3   25683.0        2586  10352347_2586.     Kecskemét              NaN   \n",
            "4   25684.0        2107  10352348_2107.     Kecskemét              NaN   \n",
            "\n",
            "   direction_id  block_id    shape_id  wheelchair_accessible  bikes_allowed  \n",
            "0           NaN       NaN  10352347.0                    NaN            NaN  \n",
            "1           NaN       NaN  10352347.0                    NaN            NaN  \n",
            "2           NaN       NaN  10352347.0                    NaN            NaN  \n",
            "3           NaN       NaN  10352347.0                    NaN            NaN  \n",
            "4           NaN       NaN  10352348.0                    NaN            NaN  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#Upload Zip file\n",
        "uploaded = files.upload()\n",
        "gtfs_filename = next(iter(uploaded))\n",
        "\n",
        "# Extract GTFS\n",
        "with zipfile.ZipFile(gtfs_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "\n",
        "# Read agency\n",
        "agency_df = pd.read_csv('agency.txt')\n",
        "print(agency_df.head())\n",
        "\n",
        "# Read calender\n",
        "calendar_df = pd.read_csv('calendar.txt')\n",
        "print(calendar_df.head())\n",
        "\n",
        "# Read routes\n",
        "routes_df = pd.read_csv('routes.txt')\n",
        "print(routes_df.head())\n",
        "\n",
        "# Read Shapes\n",
        "shapes_df = pd.read_csv('shapes.txt')\n",
        "print(shapes_df.head())\n",
        "\n",
        "# Read Stop_times\n",
        "stop_times_df = pd.read_csv('stop_times.txt')\n",
        "print(stop_times_df.head())\n",
        "\n",
        "# Read stops\n",
        "stops_df = pd.read_csv('stops.txt')\n",
        "print(stops_df.head())\n",
        "\n",
        "# Read trips\n",
        "trips_df = pd.read_csv('trips.txt')\n",
        "print(trips_df.head())\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the information for each DataFrame to get a detailed overview\n",
        "print(\"Agency DataFrame Info:\")\n",
        "print(agency_df.info())\n",
        "print(\"\\nCalendar DataFrame Info:\")\n",
        "print(calendar_df.info())\n",
        "print(\"\\nRoutes DataFrame Info:\")\n",
        "print(routes_df.info())\n",
        "print(\"\\nShapes DataFrame Info:\")\n",
        "print(shapes_df.info())\n",
        "print(\"\\nStop Times DataFrame Info:\")\n",
        "print(stop_times_df.info())\n",
        "print(\"\\nStops DataFrame Info:\")\n",
        "print(stops_df.info())\n",
        "print(\"\\nTrips DataFrame Info:\")\n",
        "print(trips_df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV_xeaTci2fu",
        "outputId": "515a97d2-b30c-4f4d-82d9-19273f3496d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agency DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 7 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   agency_id        3 non-null      int64 \n",
            " 1   agency_name      3 non-null      object\n",
            " 2   agency_url       3 non-null      object\n",
            " 3   agency_timezone  3 non-null      object\n",
            " 4   agency_lang      3 non-null      object\n",
            " 5   agency_phone     3 non-null      object\n",
            " 6   agency_fare_url  3 non-null      object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 296.0+ bytes\n",
            "None\n",
            "\n",
            "Calendar DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 773 entries, 0 to 772\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count  Dtype\n",
            "---  ------      --------------  -----\n",
            " 0   service_id  773 non-null    int64\n",
            " 1   monday      773 non-null    int64\n",
            " 2   tuesday     773 non-null    int64\n",
            " 3   wednesday   773 non-null    int64\n",
            " 4   thursday    773 non-null    int64\n",
            " 5   friday      773 non-null    int64\n",
            " 6   saturday    773 non-null    int64\n",
            " 7   sunday      773 non-null    int64\n",
            " 8   start_date  773 non-null    int64\n",
            " 9   end_date    773 non-null    int64\n",
            "dtypes: int64(10)\n",
            "memory usage: 60.5 KB\n",
            "None\n",
            "\n",
            "Routes DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8945 entries, 0 to 8944\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   route_id          8945 non-null   float64\n",
            " 1   agency_id         8945 non-null   int64  \n",
            " 2   route_short_name  3518 non-null   object \n",
            " 3   route_long_name   5635 non-null   object \n",
            " 4   route_desc        0 non-null      float64\n",
            " 5   route_type        8945 non-null   int64  \n",
            " 6   route_url         1758 non-null   object \n",
            " 7   route_color       4561 non-null   object \n",
            " 8   route_text_color  4561 non-null   object \n",
            "dtypes: float64(2), int64(2), object(5)\n",
            "memory usage: 629.1+ KB\n",
            "None\n",
            "\n",
            "Shapes DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 426778 entries, 0 to 426777\n",
            "Data columns (total 5 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   shape_id             426778 non-null  int64  \n",
            " 1   shape_pt_lat         426778 non-null  float64\n",
            " 2   shape_pt_lon         426778 non-null  float64\n",
            " 3   shape_pt_sequence    426778 non-null  int64  \n",
            " 4   shape_dist_traveled  0 non-null       float64\n",
            "dtypes: float64(3), int64(2)\n",
            "memory usage: 16.3 MB\n",
            "None\n",
            "\n",
            "Stop Times DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 246245 entries, 0 to 246244\n",
            "Data columns (total 8 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   trip_id         246245 non-null  object \n",
            " 1   arrival_time    246245 non-null  object \n",
            " 2   departure_time  246245 non-null  object \n",
            " 3   stop_id         246245 non-null  int64  \n",
            " 4   stop_sequence   246245 non-null  int64  \n",
            " 5   stop_headsign   0 non-null       float64\n",
            " 6   pickup_type     246245 non-null  int64  \n",
            " 7   drop_off_type   246245 non-null  int64  \n",
            "dtypes: float64(1), int64(4), object(3)\n",
            "memory usage: 15.0+ MB\n",
            "None\n",
            "\n",
            "Stops DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1206 entries, 0 to 1205\n",
            "Data columns (total 12 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   stop_id              1206 non-null   int64  \n",
            " 1   stop_code            0 non-null      float64\n",
            " 2   stop_name            1206 non-null   object \n",
            " 3   stop_desc            0 non-null      float64\n",
            " 4   stop_lat             1206 non-null   float64\n",
            " 5   stop_lon             1206 non-null   float64\n",
            " 6   zone_id              0 non-null      float64\n",
            " 7   stop_url             0 non-null      float64\n",
            " 8   location_type        1206 non-null   int64  \n",
            " 9   parent_station       0 non-null      float64\n",
            " 10  stop_timezone        0 non-null      float64\n",
            " 11  wheelchair_boarding  1206 non-null   int64  \n",
            "dtypes: float64(8), int64(3), object(1)\n",
            "memory usage: 113.2+ KB\n",
            "None\n",
            "\n",
            "Trips DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23189 entries, 0 to 23188\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   route_id               23189 non-null  float64\n",
            " 1   service_id             23189 non-null  int64  \n",
            " 2   trip_id                23189 non-null  object \n",
            " 3   trip_headsign          22045 non-null  object \n",
            " 4   trip_short_name        0 non-null      float64\n",
            " 5   direction_id           0 non-null      float64\n",
            " 6   block_id               0 non-null      float64\n",
            " 7   shape_id               17404 non-null  float64\n",
            " 8   wheelchair_accessible  0 non-null      float64\n",
            " 9   bikes_allowed          0 non-null      float64\n",
            "dtypes: float64(7), int64(1), object(2)\n",
            "memory usage: 1.8+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete columns with completely null values\n",
        "agency_df.dropna(axis=1, how='all', inplace=True)\n",
        "calendar_df.dropna(axis=1, how='all', inplace=True)\n",
        "routes_df.dropna(axis=1, how='all', inplace=True)\n",
        "shapes_df.dropna(axis=1, how='all', inplace=True)\n",
        "stop_times_df.dropna(axis=1, how='all', inplace=True)\n",
        "stops_df.dropna(axis=1, how='all', inplace=True)\n",
        "trips_df.dropna(axis=1, how='all', inplace=True)\n",
        "\n",
        "# Print the deleted DataFrame information\n",
        "print(\"Agency DataFrame Info After Dropping Null Columns:\")\n",
        "print(agency_df.info())\n",
        "print(\"\\nCalendar DataFrame Info After Dropping Null Columns:\")\n",
        "print(calendar_df.info())\n",
        "print(\"\\nRoutes DataFrame Info After Dropping Null Columns:\")\n",
        "print(routes_df.info())\n",
        "print(\"\\nShapes DataFrame Info After Dropping Null Columns:\")\n",
        "print(shapes_df.info())\n",
        "print(\"\\nStop Times DataFrame Info After Dropping Null Columns:\")\n",
        "print(stop_times_df.info())\n",
        "print(\"\\nStops DataFrame Info After Dropping Null Columns:\")\n",
        "print(stops_df.info())\n",
        "print(\"\\nTrips DataFrame Info After Dropping Null Columns:\")\n",
        "print(trips_df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHzSZARYkR1M",
        "outputId": "6a1640ca-a780-42ca-c52f-6cd5e8d08a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agency DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 7 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   agency_id        3 non-null      int64 \n",
            " 1   agency_name      3 non-null      object\n",
            " 2   agency_url       3 non-null      object\n",
            " 3   agency_timezone  3 non-null      object\n",
            " 4   agency_lang      3 non-null      object\n",
            " 5   agency_phone     3 non-null      object\n",
            " 6   agency_fare_url  3 non-null      object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 296.0+ bytes\n",
            "None\n",
            "\n",
            "Calendar DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 773 entries, 0 to 772\n",
            "Data columns (total 10 columns):\n",
            " #   Column      Non-Null Count  Dtype\n",
            "---  ------      --------------  -----\n",
            " 0   service_id  773 non-null    int64\n",
            " 1   monday      773 non-null    int64\n",
            " 2   tuesday     773 non-null    int64\n",
            " 3   wednesday   773 non-null    int64\n",
            " 4   thursday    773 non-null    int64\n",
            " 5   friday      773 non-null    int64\n",
            " 6   saturday    773 non-null    int64\n",
            " 7   sunday      773 non-null    int64\n",
            " 8   start_date  773 non-null    int64\n",
            " 9   end_date    773 non-null    int64\n",
            "dtypes: int64(10)\n",
            "memory usage: 60.5 KB\n",
            "None\n",
            "\n",
            "Routes DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8945 entries, 0 to 8944\n",
            "Data columns (total 8 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   route_id          8945 non-null   float64\n",
            " 1   agency_id         8945 non-null   int64  \n",
            " 2   route_short_name  3518 non-null   object \n",
            " 3   route_long_name   5635 non-null   object \n",
            " 4   route_type        8945 non-null   int64  \n",
            " 5   route_url         1758 non-null   object \n",
            " 6   route_color       4561 non-null   object \n",
            " 7   route_text_color  4561 non-null   object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 559.2+ KB\n",
            "None\n",
            "\n",
            "Shapes DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 426778 entries, 0 to 426777\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   shape_id           426778 non-null  int64  \n",
            " 1   shape_pt_lat       426778 non-null  float64\n",
            " 2   shape_pt_lon       426778 non-null  float64\n",
            " 3   shape_pt_sequence  426778 non-null  int64  \n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 13.0 MB\n",
            "None\n",
            "\n",
            "Stop Times DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 246245 entries, 0 to 246244\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   trip_id         246245 non-null  object\n",
            " 1   arrival_time    246245 non-null  object\n",
            " 2   departure_time  246245 non-null  object\n",
            " 3   stop_id         246245 non-null  int64 \n",
            " 4   stop_sequence   246245 non-null  int64 \n",
            " 5   pickup_type     246245 non-null  int64 \n",
            " 6   drop_off_type   246245 non-null  int64 \n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 13.2+ MB\n",
            "None\n",
            "\n",
            "Stops DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1206 entries, 0 to 1205\n",
            "Data columns (total 6 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   stop_id              1206 non-null   int64  \n",
            " 1   stop_name            1206 non-null   object \n",
            " 2   stop_lat             1206 non-null   float64\n",
            " 3   stop_lon             1206 non-null   float64\n",
            " 4   location_type        1206 non-null   int64  \n",
            " 5   wheelchair_boarding  1206 non-null   int64  \n",
            "dtypes: float64(2), int64(3), object(1)\n",
            "memory usage: 56.7+ KB\n",
            "None\n",
            "\n",
            "Trips DataFrame Info After Dropping Null Columns:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23189 entries, 0 to 23188\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   route_id       23189 non-null  float64\n",
            " 1   service_id     23189 non-null  int64  \n",
            " 2   trip_id        23189 non-null  object \n",
            " 3   trip_headsign  22045 non-null  object \n",
            " 4   shape_id       17404 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 905.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 例如，对于数值数据，计算描述性统计量\n",
        "print(stop_times_df['arrival_time'].describe())\n",
        "\n",
        "# 对于类别数据，查看类别分布\n",
        "print(routes_df['route_type'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ewXC-l6kR5K",
        "outputId": "6af5b3f0-cf17-43e9-a689-393763c5150d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count       246245\n",
            "unique        1686\n",
            "top       07:10:00\n",
            "freq           346\n",
            "Name: arrival_time, dtype: object\n",
            "2    7187\n",
            "3    1758\n",
            "Name: route_type, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "QD_PxcD3c8Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the structure and column names of trips_df\n",
        "print(\"trips_df :\")\n",
        "print(trips_df.head())\n",
        "print(trips_df.columns)\n",
        "# Check the structure and column names of stop_times_df\n",
        "print(\"stop_times_df :\")\n",
        "print(stop_times_df.head())\n",
        "print(stop_times_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNSQb0KYD7Yi",
        "outputId": "5308cdde-ce3c-4f29-b273-85ba0c56786e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trips_df :\n",
            "   route_id  service_id         trip_id trip_headsign    shape_id\n",
            "0   25683.0        2107  10352347_2107.     Kecskemét  10352347.0\n",
            "1   25683.0        2409  10352347_2409.     Kecskemét  10352347.0\n",
            "2   25683.0        2585  10352347_2585.     Kecskemét  10352347.0\n",
            "3   25683.0        2586  10352347_2586.     Kecskemét  10352347.0\n",
            "4   25684.0        2107  10352348_2107.     Kecskemét  10352348.0\n",
            "Index(['route_id', 'service_id', 'trip_id', 'trip_headsign', 'shape_id'], dtype='object')\n",
            "stop_times_df :\n",
            "          trip_id arrival_time departure_time  stop_id  stop_sequence  \\\n",
            "0  10352347_2107.     18:47:00       18:47:00     6096          11270   \n",
            "1  10352347_2107.     18:50:00       18:50:00     1895          11300   \n",
            "2  10352347_2107.     18:51:00       18:51:00     1896          11310   \n",
            "3  10352347_2107.     18:56:00       18:57:00     6097          11370   \n",
            "4  10352347_2107.     18:59:00       19:00:00      490          11400   \n",
            "\n",
            "   pickup_type  drop_off_type  \n",
            "0            0              0  \n",
            "1            0              0  \n",
            "2            0              0  \n",
            "3            0              0  \n",
            "4            0              0  \n",
            "Index(['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence',\n",
            "       'pickup_type', 'drop_off_type'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将时刻表中的发车时间从字符串转换为时间类型\n",
        "stop_times_df['departure_time'] = pd.to_timedelta(stop_times_df['departure_time'])\n",
        "\n",
        "# 提取小时信息\n",
        "stop_times_df['hour'] = stop_times_df['departure_time'].dt.components.hours\n",
        "\n",
        "# 计算每小时每个路线的发车次数\n",
        "hourly_departures = stop_times_df.groupby(['route_id', 'hour']).size().reset_index(name='departures_per_hour')\n",
        "print(hourly_departures.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9k6s_FtHxkP",
        "outputId": "18bf2442-b53d-48cc-ad82-dc57c14272bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   route_id  hour  departures_per_hour\n",
            "0      1003    11                   50\n",
            "1      1004     9                   30\n",
            "2      1005     5                   30\n",
            "3      1006    17                   50\n",
            "4      1007    15                   30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 假设高峰小时为早上7到9点，下午5到7点\n",
        "peak_hours = hourly_departures[(hourly_departures['hour'] >= 7) & (hourly_departures['hour'] <= 9) | (hourly_departures['hour'] >= 17) & (hourly_departures['hour'] <= 19)]\n",
        "\n",
        "# 可以进一步分析这些高峰小时的发车频率\n",
        "peak_hours_analysis = peak_hours.groupby('route_id')['departures_per_hour'].mean().reset_index()\n",
        "print(peak_hours_analysis.sort_values(by='departures_per_hour', ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw81JADL4Sxe",
        "outputId": "d24f9182-f629-47c5-f775-49791ea60bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      route_id  departures_per_hour\n",
            "1927     26182                220.0\n",
            "1917     26148                200.0\n",
            "1899     26087                180.0\n",
            "1926     26165                120.0\n",
            "1908     26132                100.0\n",
            "...        ...                  ...\n",
            "2993     40768                  1.0\n",
            "2994     40769                  1.0\n",
            "308       3971                  1.0\n",
            "648       7151                  1.0\n",
            "3617     48708                  1.0\n",
            "\n",
            "[3858 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense"
      ],
      "metadata": {
        "id": "TRMrSXtW6yXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 由于我们没有真实的乘客数据，这里我们创建一个随机数据集来模拟\n",
        "np.random.seed(42)  # 保证结果可重现\n",
        "mock_passenger_data = np.random.randint(1, 100, size=(hourly_departures.shape[0],))\n",
        "hourly_departures['passenger_count'] = mock_passenger_data\n",
        "\n",
        "# 归一化数据\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_features = scaler.fit_transform(hourly_departures[['departures_per_hour', 'passenger_count']])\n"
      ],
      "metadata": {
        "id": "igvt2DkL4TAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割数据集为训练集和测试集\n",
        "train_size = int(len(scaled_features) * 0.80)\n",
        "test_size = len(scaled_features) - train_size\n",
        "train, test = scaled_features[0:train_size,:], scaled_features[train_size:len(scaled_features),:]\n",
        "\n",
        "# LSTM需要输入数据的格式为[samples, time steps, features]，以下是转换数据的函数\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back - 1):\n",
        "        a = dataset[i:(i + look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 1])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 1\n",
        "X_train, Y_train = create_dataset(train, look_back)\n",
        "X_test, Y_test = create_dataset(test, look_back)\n",
        "\n",
        "# 为LSTM模型重塑输入数据\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# 创建并训练LSTM网络\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(X_train, Y_train, epochs=5, batch_size=1, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSwuAxwG4TCy",
        "outputId": "4d9d8b80-e5cd-4da1-d326-942cef8655b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "15379/15379 - 28s - loss: 0.0872 - 28s/epoch - 2ms/step\n",
            "Epoch 2/5\n",
            "15379/15379 - 27s - loss: 0.0855 - 27s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "15379/15379 - 27s - loss: 0.0854 - 27s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "15379/15379 - 28s - loss: 0.0855 - 28s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "15379/15379 - 29s - loss: 0.0854 - 29s/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e8c70c2cd90>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预测\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# 反归一化预测值\n",
        "train_predict = scaler.inverse_transform(np.concatenate((train_predict, np.zeros((train_predict.shape[0], 1))), axis=1))[:,0]\n",
        "Y_train = scaler.inverse_transform(np.concatenate((np.reshape(Y_train, (Y_train.shape[0], 1)), np.zeros((Y_train.shape[0], 1))), axis=1))[:,0]\n",
        "\n",
        "# 计算均方根误差\n",
        "train_score = np.sqrt(np.mean((Y_train - train_predict) ** 2))\n",
        "print(f'Train Score: {train_score:.2f} RMSE')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFld8Thu6mXq",
        "outputId": "4b8411ab-b40f-4c20-bd9f-e6df25c574c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "481/481 [==============================] - 1s 2ms/step\n",
            "121/121 [==============================] - 0s 2ms/step\n",
            "Train Score: 63.88 RMSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 假设您的stop_times_df中的arrival_time已经是timedelta类型\n",
        "# 将arrival_time转换为一天中的分钟数\n",
        "stop_times_df['arrival_time_min'] = stop_times_df['arrival_time'].dt.seconds / 60\n",
        "\n",
        "# 从service_date中提取出星期几（0=星期一，6=星期日）\n",
        "stop_times_df['weekday'] = stop_times_df['service_date'].dt.weekday\n",
        "\n",
        "# 创建一个二元特征，表明这是否为周末\n",
        "stop_times_df['is_weekend'] = (stop_times_df['weekday'] >= 5).astype(int)\n",
        "# 以小时为单位聚合数据\n",
        "# 首先，您需要一个小时的列\n",
        "stop_times_df['hour'] = stop_times_df['arrival_time'].dt.components.hours\n",
        "\n",
        "# 然后根据路线ID、日期和小时聚合数据\n",
        "hourly_counts = stop_times_df.groupby(['route_id', 'service_date', 'hour']).size().reset_index(name='passenger_count')\n",
        "# 以小时为单位聚合数据\n",
        "# 首先，您需要一个小时的列\n",
        "stop_times_df['hour'] = stop_times_df['arrival_time'].dt.components.hours\n",
        "\n",
        "# 然后根据路线ID、日期和小时聚合数据\n",
        "hourly_counts = stop_times_df.groupby(['route_id', 'service_date', 'hour']).size().reset_index(name='passenger_count')\n",
        "# 这个过程可能相当复杂，通常需要自定义函数\n",
        "# 下面的代码是一个示例，表示如何为每个路线和每个小时创建一个历史窗口的特征\n",
        "def create_lagged_features(df, n_lags=3):\n",
        "    lagged_df = pd.DataFrame()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        lagged_series = df.groupby(['route_id', 'service_date'])['passenger_count'].shift(lag, fill_value=0)\n",
        "        lagged_df[f'lag_{lag}'] = lagged_series\n",
        "    return lagged_df\n",
        "\n",
        "# 创建滞后特征\n",
        "lagged_features = create_lagged_features(hourly_counts)\n",
        "hourly_counts = pd.concat([hourly_counts, lagged_features], axis=1)\n",
        "# 对route_type进行独热编码\n",
        "routes_df = pd.get_dummies(routes_df, columns=['route_type'], prefix='type')\n",
        "# 初始化标准化器\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 标准化乘客计数\n",
        "hourly_counts['passenger_count'] = scaler.fit_transform(hourly_counts[['passenger_count']])\n",
        "# 按照日期来划分数据集，例如\n",
        "train_data = hourly_counts[hourly_counts['service_date'] < pd.Timestamp('2022-01-01')]\n",
        "test_data = hourly_counts[hourly_counts['service_date'] >= pd.Timestamp('2022-01-01')]\n",
        "\n",
        "# 分离特征和标签\n",
        "X_train = train_data.drop('passenger_count', axis=1)\n",
        "y_train = train_data['passenger_count']\n",
        "X_test = test_data.drop('passenger_count', axis=1)\n",
        "y_test = test_data['passenger_count']\n",
        "# 假定您已经创建了hourly_counts DataFrame\n",
        "# 创建滞后特征，例如使用过去3个小时的乘客量\n",
        "for lag in range(1, 4):\n",
        "    hourly_counts[f'lag_{lag}'] = hourly_counts.groupby(['route_id'])['passenger_count'].shift(lag)\n",
        "\n",
        "# 删除因创建滞后特征而产生的任何NaN值\n",
        "hourly_counts.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "0m8Mopbu6maJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Dataset"
      ],
      "metadata": {
        "id": "M1rm-nXKyviE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is recorded on an hourly basis and may be divided at the end of the last full week or month\n",
        "split_date = pd.to_datetime('2023-10-01')\n",
        "\n",
        "\n",
        "# Delineate data sets\n",
        "train = hourly_counts[hourly_counts['service_date'] < split_date]\n",
        "test = hourly_counts[hourly_counts['service_date'] >= split_date]\n"
      ],
      "metadata": {
        "id": "XJFmHp0CzARD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set shape:\", train.shape)\n",
        "print(\"Test set shape:\", test.shape)\n"
      ],
      "metadata": {
        "id": "2-I4_M1J2CZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876027e8-2652-4d5d-9db5-d2a3a63ed8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (0, 7)\n",
            "Test set shape: (0, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that service_date is of type datetime\n",
        "train['service_date'] = pd.to_datetime(train['service_date'])\n",
        "test['service_date'] = pd.to_datetime(test['service_date'])\n",
        "\n",
        "# create 'weekday' feature (Monday=0, Sunday=6)\n",
        "train['weekday'] = train['service_date'].dt.weekday\n",
        "test['weekday'] = test['service_date'].dt.weekday\n",
        "\n",
        "# create 'is_weekend' feature (weekend=1, non-weekend=0)\n",
        "train['is_weekend'] = (train['weekday'] >= 5).astype(int)\n",
        "test['is_weekend'] = (test['weekday'] >= 5).astype(int)\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_test = test[features]\n",
        "y_test = test[target]\n"
      ],
      "metadata": {
        "id": "xiBcZywAxHmT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "82a6e218-9a9b-41f8-e700-c44247ce9888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-7d5cbd598827>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_weekend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n"
      ],
      "metadata": {
        "id": "So8HEAOV1Zdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Nomalization"
      ],
      "metadata": {
        "id": "3NXHJTKWy2FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Instantiate standardisers\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Training set feature normalisation\n",
        "X_train = train[features]\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "\n",
        "# Normalisation of test set features (using parameters learned from the training set)\n",
        "X_test = test[features]\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "aXOYKlTSxFsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(input_data, target_data, time_steps):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(input_data) - time_steps):\n",
        "        v = input_data.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(target_data.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "# Use functions to create training and test sequences\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train, time_steps)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test, y_test, time_steps)\n",
        "\n",
        "# Reshape Data\n",
        "X_train_reshaped = X_train_seq.reshape((X_train_seq.shape[0], time_steps, n_features))\n",
        "X_test_reshaped = X_test_seq.reshape((X_test_seq.shape[0], time_steps, n_features))\n"
      ],
      "metadata": {
        "id": "eKI6vlnR4JOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model"
      ],
      "metadata": {
        "id": "DhOUHKff5FT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model"
      ],
      "metadata": {
        "id": "yiI46gKw5Iuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the LSTM model structure\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(time_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n"
      ],
      "metadata": {
        "id": "8aqxyDhDy5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the LSTM model"
      ],
      "metadata": {
        "id": "j0Gdl3bq5RgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "history = model.fit(\n",
        "    X_train_reshaped,\n",
        "    y_train_seq,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_seq),\n",
        "    verbose=1,\n",
        "    shuffle=False\n",
        ")\n",
        "# Calculate average training loss and validation loss\n",
        "average_loss = sum(history.history['loss']) / len(history.history['loss'])\n",
        "average_val_loss = sum(history.history['val_loss']) / len(history.history['val_loss'])\n",
        "\n",
        "print(f'Average training loss: {average_loss}')\n",
        "print(f'Average validation loss: {average_val_loss}')"
      ],
      "metadata": {
        "id": "MVo7Ilfu5QDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "qnuDcpnm5X4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "# Predictions using the test set\n",
        "y_pred = model.predict(X_test_reshaped)\n",
        "\n",
        "# Evaluate model performance\n",
        "mse = mean_squared_error(y_test_seq, y_pred)\n",
        "rmse = sqrt(mean_squared_error(y_test_seq, y_pred))\n",
        "mae = mean_absolute_error(y_test_seq, y_pred)\n",
        "r2 = r2_score(y_test_seq, y_pred)\n",
        "\n",
        "# Calculate MAPE - Mean Absolute Percentage Error\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    non_zero_index = (y_true != 0)\n",
        "    y_true = y_true[non_zero_index]\n",
        "    y_pred = y_pred[non_zero_index]\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(y_test_seq, y_pred)\n",
        "\n",
        "# Print out the metrics\n",
        "print('Test MSE:', mse)\n",
        "print('Test RMSE:', rmse)\n",
        "print('Test MAE:', mae)\n",
        "print('Test R2:', r2)\n",
        "print('Test MAPE:', mape)\n"
      ],
      "metadata": {
        "id": "oZtbGXmz5QIG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}